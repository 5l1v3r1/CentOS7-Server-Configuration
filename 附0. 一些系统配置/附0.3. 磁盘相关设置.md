## 附0.3. 磁盘相关设置

### 附0.3.1. 添加硬盘

这是添加新硬盘时创建分区的示例。

`fdisk /dev/sdb` # 进入分区操作模式

```
Welcome to fdisk (util-linux 2.23.2).

Changes will remain in memory only, until you decide to write them.
Be careful before using the write command.

Command (m for help): p  # 显示分区表

Disk /dev/vdb: 21.5 GB, 21474836480 bytes, 41943040 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk label type: dos
Disk identifier: 0xd97d5b18

   Device Boot      Start         End      Blocks   Id  System
   # 没有
Command (m for help): n  # 创建分区
Partition type:
   p   primary (0 primary, 0 extended, 4 free)
   e   extended
Select (default p): p  # 主分区
Partition number (1-4, default 1): 1  # 指定分区号
First sector (2048-41943039, default 2048):  # 起始扇区
Using default value 2048
Last sector, +sectors or +size{K,M,G} (2048-41943039, default 41943039):  # 结束扇区
Using default value 41943039
Partition 1 of type Linux and of size 20 GiB is set

Command (m for help): p  # 显示分区表

Disk /dev/vdb: 21.5 GB, 21474836480 bytes, 41943040 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk label type: dos
Disk identifier: 0xd97d5b18

   Device Boot      Start         End      Blocks   Id  System
/dev/vdb1            2048    41943039    20970496   83  Linux
   # 已创建
Command (m for help): t  # 更改类型，如果不适应逻辑卷，不用更改

Selected partition 1
Hex code (type L to list all codes): L  # 显示列表
 0  Empty           24  NEC DOS         81  Minix / old Lin bf  Solaris
 1  FAT12           27  Hidden NTFS Win 82  Linux swap / So c1  DRDOS/sec (FAT-
 2  XENIX root      39  Plan 9          83  Linux           c4  DRDOS/sec (FAT-
 3  XENIX usr       3c  PartitionMagic  84  OS/2 hidden C:  c6  DRDOS/sec (FAT-
 4  FAT16 <32M      40  Venix 80286     85  Linux extended  c7  Syrinx
 5  Extended        41  PPC PReP Boot   86  NTFS volume set da  Non-FS data
 6  FAT16           42  SFS             87  NTFS volume set db  CP/M / CTOS / .
 7  HPFS/NTFS/exFAT 4d  QNX4.x          88  Linux plaintext de  Dell Utility
 8  AIX             4e  QNX4.x 2nd part 8e  Linux LVM       df  BootIt
 9  AIX bootable    4f  QNX4.x 3rd part 93  Amoeba          e1  DOS access
 a  OS/2 Boot Manag 50  OnTrack DM      94  Amoeba BBT      e3  DOS R/O
 b  W95 FAT32       51  OnTrack DM6 Aux 9f  BSD/OS          e4  SpeedStor
 c  W95 FAT32 (LBA) 52  CP/M            a0  IBM Thinkpad hi eb  BeOS fs
 e  W95 FAT16 (LBA) 53  OnTrack DM6 Aux a5  FreeBSD         ee  GPT
 f  W95 Ext'd (LBA) 54  OnTrackDM6      a6  OpenBSD         ef  EFI (FAT-12/16/
10  OPUS            55  EZ-Drive        a7  NeXTSTEP        f0  Linux/PA-RISC b
11  Hidden FAT12    56  Golden Bow      a8  Darwin UFS      f1  SpeedStor
12  Compaq diagnost 5c  Priam Edisk     a9  NetBSD          f4  SpeedStor
14  Hidden FAT16 <3 61  SpeedStor       ab  Darwin boot     f2  DOS secondary
16  Hidden FAT16    63  GNU HURD or Sys af  HFS / HFS+      fb  VMware VMFS
17  Hidden HPFS/NTF 64  Novell Netware  b7  BSDI fs         fc  VMware VMKCORE
18  AST SmartSleep  65  Novell Netware  b8  BSDI swap       fd  Linux raid auto
1b  Hidden W95 FAT3 70  DiskSecure Mult bb  Boot Wizard hid fe  LANstep
1c  Hidden W95 FAT3 75  PC/IX           be  Solaris boot    ff  BBT
1e  Hidden W95 FAT1 80  Old Minix
Hex code (type L to list all codes): 8e  # 指定Linux LVM
Changed type of partition 'Linux' to 'Linux LVM'

Command (m for help): p  # 显示分区表

Disk /dev/vdb: 21.5 GB, 21474836480 bytes, 41943040 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk label type: dos
Disk identifier: 0xd97d5b18

   Device Boot      Start         End      Blocks   Id  System
/dev/vdb1            2048    41943039    20970496   8e  Linux LVM
   # 已更改
Command (m for help): w  # 保存并退出
The partition table has been altered!

Calling ioctl() to re-read partition table.

WARNING: Re-reading the partition table failed with error 16: Device or resource busy.
The kernel still uses the old table. The new table will be used at
the next reboot or after you run partprobe(8) or kpartx(8)
Syncing disks.
```

`sfdisk -l /dev/sdb` # 显示状态

```
Disk /dev/vdb: 41610 cylinders, 16 heads, 63 sectors/track
sfdisk: Warning: The partition table looks like it was made
  for C/H/S=*/3/34 (instead of 41610/16/63).
For this listing I'll assume that geometry.

Units: cylinders of 52224 bytes, blocks of 1024 bytes, counting from 0

   Device Boot Start     End   #cyls    #blocks   Id  System
/dev/vdb1         20+ 411206- 411187-  20970496   8e  Linux LVM
sfdisk:                 start: (c,h,s) expected (20,0,9) found (2,0,33)

sfdisk:                 end: (c,h,s) expected (1023,2,34) found (650,2,34)

/dev/vdb2          0       -       0          0    0  Empty
/dev/vdb3          0       -       0          0    0  Empty
/dev/vdb4          0       -       0          0    0  Empty
```

不使用逻辑卷，则格式化分区后挂载（如挂载到`/mnt/storage`）即可：

```
mkfs.xfs /dev/sdb1  # 使用xfs文件系统
mkfs.ext4 /dev/sdb1  # 使用ext4文件系统
mkdir /mnt/storage
mount /dev/sdb1 /mnt/storage
```

添加到`/etc/fstab`，系统启动时挂载：

```
# 加入以下一行，具体含义可以网上查下资料
/dev/sdb1 /mnt/storage xfs defaults 0 0
```

### 附0.3.2. 显示硬盘信息

安装hdparm：

`yum -y install hdparm`

显示硬盘信息：

`hdparm -i /dev/sda`

```
/dev/sda:

 Model=TOSHIBA THNSNH128GCST, FwRev=HTRAN101, SerialNo=Y3TS108TTPEY
 Config={ Fixed }
 RawCHS=16383/16/63, TrkSize=0, SectSize=0, ECCbytes=0
 BuffType=unknown, BuffSize=unknown, MaxMultSect=16, MultSect=16
 CurCHS=16383/16/63, CurSects=16514064, LBA=yes, LBAsects=250069680
 IORDY=on/off, tPIO={min:120,w/IORDY:120}, tDMA={min:120,rec:120}
 PIO modes:  pio0 pio3 pio4
 DMA modes:  mdma0 mdma1 mdma2
 UDMA modes: udma0 udma1 udma2 udma3 udma4 *udma5
 AdvancedPM=yes: unknown setting WriteCache=enabled
 Drive conforms to: Unspecified:  ATA/ATAPI-3,4,5,6,7

 * signifies the current active mode
```

`hdparm -I /dev/sda` # 显示细节

```
/dev/sda:

ATA device, with non-removable media
        Model Number:       TOSHIBA THNSNH128GCST
        Serial Number:      Y3TS108TTPEY
        Firmware Revision:  HTRAN101
        Transport:          Serial, ATA8-AST, SATA 1.0a, SATA II Extensions, SATA Rev 2.5, SATA Rev 2.6, SATA Rev 3.0
Standards:
        Supported: 9 8 7 6 5
        Likely used: 9
Configuration:
        Logical         max     current
        cylinders       16383   16383
        heads           16      16
        sectors/track   63      63
.....
.....
```

显示硬盘的设置：

`hdparm /dev/sda`

```
/dev/sda:
 multcount     = 16 (on)
 IO_support    =  1 (32-bit)
 readonly      =  0 (off)
 readahead     = 256 (on)
 geometry      = 15566/255/63, sectors = 250069680, start = 0
```

测试硬盘的可读速度：

`hdparm -Tt /dev/sda`

```
/dev/sda:
 Timing cached reads:   21468 MB in  2.00 seconds = 10746.50 MB/sec
 Timing buffered disk reads: 1458 MB in  3.00 seconds = 485.64 MB/sec
```

### 附0.3.3. 设置磁盘配额

设置磁盘配额以限制磁盘使用量。

#### 附0.3.3.1. XFS

下例演示在**XFS格式**的`/home`上设置配额。

添加挂载选项以启用配额：

`umount /home`

`mount -o uquota,gquota /dev/sdb1 /home`

编辑`/etc/fstab`文件：

```
# 添加选项
/dev/mapper/centos-root /           xfs   defaults               0 0
UUID=c4df086e-3699-4e02-b7cf  /boot xfs   defaults               0 0
/dev/mapper/centos-swap swap        swap  defaults               0 0
/dev/sdb1               /home       xfs   defaults,uquota,gquota 0 0
```

设置用户配额。例如，将配额应用于用户“cent”：

`xfs_quota -x /home` # 以专家模式运行配额工具

```
# 显示当前状态
xfs_quota> state
User quota state on /home (/dev/sdb1)
  Accounting: ON
  Enforcement: ON
  Inode: #136 (2 blocks, 2 extents)
Group quota state on /home (/dev/sdb1)
  Accounting: ON
  Enforcement: ON
  Inode: #137 (2 blocks, 2 extents)
Project quota state on /home (/dev/sdb1)
  Accounting: OFF
  Enforcement: OFF
  Inode: #137 (2 blocks, 2 extents)
Blocks grace time: [7 days 00:00:30]
Inodes grace time: [7 days 00:00:30]
Realtime Blocks grace time: [7 days 00:00:30]

# 显示使用情况报告
xfs_quota> report -h
User quota on /home (/dev/sdb1)
                        Blocks
User ID      Used   Soft   Hard Warn/Grace
---------- ---------------------------------
root            0      0      0  00 [------]
cent          16K      0      0  00 [------]

Group quota on /home (/dev/sdb1)
                        Blocks
Group ID     Used   Soft   Hard Warn/Grace
---------- ---------------------------------
root            0      0      0  00 [------]
cent          16K      0      0  00 [------]

# 给用户“cent”设置软限制9G，硬限制10G（使用千字节指定）
xfs_quota> limit bsoft=9g bhard=10g cent

# 显示报告
xfs_quota> report -h -u
User quota on /home (/dev/sdb1)
                        Blocks
User ID      Used   Soft   Hard Warn/Grace
---------- ---------------------------------
root            0      0      0  00 [------]
cent          16K     9G    10G  00 [------]
```

如果设置组配额，执行以下操作：

`xfs_quota -x -c 'limit -g bsoft=9g bhard=10g cent' /home` # 可以设置为非交互模式（non-interactive mode）

`xfs_quota -x -c 'report -h -g' /home`

```
Group quota on /home (/dev/sdb1)
                        Blocks
Group ID     Used   Soft   Hard Warn/Grace
---------- ---------------------------------
root            0      0      0  00 [------]
cent          16K     9G    10G  00 [------]
```

可以使用Warnquota发送警告（需要[SMTP服务器](../9. 邮件服务器/9.1. 安装Postfix.html)）：

`yum -y install quota-warnquota` # 安装Warnquota

编辑`/etc/quotatab`文件：

```
# 添加设备和描述配额设置
/dev/sdb1: Your Home Director
```

`sed -i -e "s/example\.com/server\.world/g" /etc/warnquota.conf` # 将域名更改为自己的域名

`warnquota -s` # 运行Warnquota

```
# 如果用户在warnquota运行时超出配额，则发送以下警告
From root@dlp.srv.world  Thu Oct 20 19:08:08 2015
Return-Path: <root@dlp.srv.world>
X-Original-To: cent
Delivered-To: cent@dlp.srv.world
From: root@srv.world
Reply-To: root@srv.world
Subject: NOTE: You are exceeding your allocated disk space limits
To: cent@dlp.srv.world
Cc: root@srv.world
Content-Type: text/plain; charset=UTF-8
Content-Disposition: inline
Date: Thu, 20 Oct 2015 19:08:08 +0900 (JST)
Status: R

Your disk usage has exceeded the agreed limits on this server
Please delete any unnecessary files on following filesystems:

Your Home Directory (/dev/sdb1)

                        Block limits               File limits
Filesystem           used    soft    hard  grace    used  soft  hard  grace
/dev/sdb1      +-   4112M   4096M   5120M  6days       6     0     0

root@srv.world
```

#### 附0.3.3.2. ext4

下例演示在**ext4格式**的`/home`上设置配额。

安装配额工具：

`yum -y install quota`

添加挂载选项以启用配额：

`umount /home`

`mount -o usrquota,grpquota /dev/sdb1 /home`

编辑`/etc/fstab`文件：

```
# 添加选项
/dev/mapper/VolGroup-lv_root /          ext4    defaults        1 1
UUID=cf3f9660-e40d-459d-8763 /boot      ext4    defaults        1 2
/dev/mapper/VolGroup-lv_swap swap       swap    defaults        0 0
tmpfs                        /dev/shm   tmpfs   defaults        0 0
devpts                       /dev/pts   devpts  gid=5,mode=620  0 0
sysfs                        /sys       sysfs   defaults        0 0
proc                         /proc      proc    defaults        0 0
/dev/sdb1                    /home      xfs     defaults,usrquota,grpquota 0 0
```

设置用户配额。例如，将配额应用于用户“cent”：

`quotacheck -um /home` # 创建配额配置

`quotaon -uv /home` # 启用配额

```
/dev/sdb1 [/home]: user quotas turned on
```

`quotaon -ap` # 显示状态

```
group quota on /home (/dev/sdb1) is off
user quota on /home (/dev/sdb1) is on
```

`edquota -u cent` # 为用户“cent”设置配额

```
# 设置软限制4G，硬限制5G（使用千字节指定）
Disk quotas for user cent (uid 500):
  Filesystem   blocks     soft       hard   inodes   soft   hard
  /dev/sdb1    16      4096000    5120000        7      0      0
```

`repquota -au` # 显示状态

```
*** Report for user quotas on device /dev/sdb1
Block grace time: 7days; Inode grace time: 7days
                        Block limits                File limits
User            used    soft    hard  grace    used  soft  hard  grace
----------------------------------------------------------------------
root      --      20       0       0              2     0     0
cent      --      16 4096000 5120000              4     0     0
```

如果要将用户的配额设置应用于其他用户，如下进行设置：

`edquota -p cent fedora` # 将“cent”的设置应用于“fedora”

`repquota -au`

```
*** Report for user quotas on device /dev/sdb1
Block grace time: 7days; Inode grace time: 7days
                        Block limits                File limits
User            used    soft    hard  grace    used  soft  hard  grace
----------------------------------------------------------------------
root      --      20       0       0              2     0     0
cent      +- 5120000 4096000 5120000  6days       7     0     0
fedora    --       4 4096000 5120000              4     0     0
```

设置组配额。例如，将配额应用于组“cent”：

`quotacheck -gm /home` # 创建配额配置

`quotaon -gv /home` # 启用配额

```
/dev/sdb1 [/home]: group quotas turned on
```

`quotaon -ap` # 显示状态

```
group quota on /home (/dev/sdb1) is on
user quota on /home (/dev/sdb1) is on
```

`edquota -g cent` # 为“cent”设置配额

```
# 设置软限制4G，硬限制5G（使用千字节指定）
Disk quotas for group cent (gid 500):
  Filesystem       blocks       soft       hard     inodes   soft   hard
  /dev/sdb1       5120000    4096000    5120000          7      0      0
```

`repquota -ag` # 显示状态

```
*** Report for group quotas on device /dev/sdb1
Block grace time: 7days; Inode grace time: 7days
                        Block limits                File limits
Group           used    soft    hard  grace    used  soft  hard  grace
----------------------------------------------------------------------
root      --      20       0       0              2     0     0
cent      +- 5120000 4096000 5120000  6days       7     0     0
fedora    --      16       0       0              4     0     0
```

可以使用Warnquota发送警告（需要[SMTP服务器](../9. 邮件服务器/9.1. 安装Postfix.html)）：

编辑`/etc/quotatab`文件：

```
# 添加设备和描述配额设置
/dev/sdb1: Your Home Director
```

`sed -i -e "s/example\.com/server\.world/g" /etc/warnquota.conf` # 将域名更改为自己的域名

`warnquota -s` # 运行Warnquota

```
# 如果用户在warnquota运行时超出配额，则发送以下警告
From root@dlp.srv.world  Fri Oct 23 09:38:10 2011
Return-Path: <root@dlp.srv.world>
X-Original-To: cent
Delivered-To: cent@dlp.srv.world
From: root@srv.world
Reply-To: root@srv.world
Subject: NOTE: You are exceeding your allocated disk space limits
To: cent@dlp.srv.world
Cc: root@srv.world
Date: Fri, 23 Oct 2011 09:38:10 +0900 (JST)
Status: R

Your disk usage has exceeded the agreed limits on this server
Please delete any unnecessary files on following filesystems:

Your Home Director (/dev/sdb1)

                        Block limits               File limits
Filesystem           used    soft    hard  grace    used  soft  hard  grace
/dev/sdb1      +-   5000M   4000M   5000M  6days       7     0     0

root@srv.world
```

### 附0.3.4. 使用SSHFS挂载

可以使用[SSHFS](https://github.com/libfuse/sshfs)通过SSH挂载另一台主机的文件系统。

安装fuse-sshfs：

`yum --enablerepo=epel -y install fuse-sshfs` # 从EPEL安装

例如，使用用户“cent”挂载另一台主机上的`/home/cent`：

`mkdir ~/sshmnt` # 为挂载创建一个目录

`sshfs 10.0.0.31:/home/cent ~/sshmnt` # 使用SSHFS挂载

```
cent@10.0.0.31's password:  # SSH密码
```

`df -hT`

```
Filesystem              Type        Size  Used Avail Use% Mounted on
/dev/mapper/centos-root xfs          27G  1.1G   26G   5% /
devtmpfs                devtmpfs    2.0G     0  2.0G   0% /dev
tmpfs                   tmpfs       2.0G     0  2.0G   0% /dev/shm
tmpfs                   tmpfs       2.0G  8.3M  2.0G   1% /run
tmpfs                   tmpfs       2.0G     0  2.0G   0% /sys/fs/cgroup
/dev/vda1               xfs         497M  151M  347M  31% /boot
10.0.0.31:/home/cent    fuse.sshfs   27G  1.1G   26G   4% /home/cent/sshmnt
# 已挂载
```

`fusermount -u ~/sshmnt` # 卸载

### 附0.3.5. 配置RAID 1

在服务器上添加两个新硬盘配置RAID 1。

本例演示新增硬盘“sdb”和“sdc”并配置RAID 1。

`df -h`

```
Filesystem               Size  Used Avail Use% Mounted on
/dev/mapper/centos-root  196G  1.2G  195G   1% /
devtmpfs                 1.9G     0  1.9G   0% /dev
tmpfs                    1.9G     0  1.9G   0% /dev/shm
tmpfs                    1.9G  8.5M  1.9G   1% /run
tmpfs                    1.9G     0  1.9G   0% /sys/fs/cgroup
/dev/sda1                497M  222M  276M  45% /boot
```

在新硬盘上创建一个分区并设置RAID标志：

`parted --script /dev/sdb "mklabel gpt"`

`parted --script /dev/sdc "mklabel gpt"`

`parted --script /dev/sdb "mkpart primary 0% 100%"`

`parted --script /dev/sdc "mkpart primary 0% 100%"`

`parted --script /dev/sdb "set 1 raid on"`

`parted --script /dev/sdc "set 1 raid on"`

配置RAID 1：

`yum -y install mdadm`

`mdadm --create /dev/md0 --level=raid1 --raid-devices=2 /dev/sdb1 /dev/sdc1`

```
mdadm: Note: this array has metadata at the start and
    may not be suitable as a boot device.  If you plan to
    store '/boot' on this device please ensure that
    your boot-loader understands md/v1.x metadata, or use
    --metadata=0.90
Continue creating array? y
mdadm: Defaulting to version 1.2 metadata
mdadm: array /dev/md0 started.
```

`cat /proc/mdstat` # 显示状态

```
Personalities : [raid1]
md0 : active raid1 sdc1[1] sdb1[0]
      83818496 blocks super 1.2 [2/2] [UU]
      [======>..............]  resync = 31.0% (26044416/83818496) finish=4.7min speed=201190K/sec

unused devices: <none>
```

`cat /proc/mdstat` # 几个小时后，如果同步完成，状态如下

```
Personalities : [raid1]
md0 : active raid1 sdc1[1] sdb1[0]
      83818496 blocks super 1.2 [2/2] [UU]

unused devices: <none>
```

编辑`/etc/sysconfig/raid-check`文件：

```
# 添加要由Cron检查的RAID设备
CHECK_DEVS="md0"
```

例如，如果RAID阵列中的成员硬盘出现故障，如下重配置RAID 1：

`cat /proc/mdstat` # 失败的状态如下

```
Personalities : [raid1]
md0 : active (auto-read-only) raid1 sdb1[0]
      83818496 blocks super 1.2 [2/1] [U_]

unused devices: <none>
```

`mdadm --manage /dev/md0 --add /dev/sdc1` # 更换新磁盘后，重新配置

```
mdadm: added /dev/sdc1
```

`cat /proc/mdstat`

```
Personalities : [raid1]
md0 : active raid1 sdc1[1] sdb1[0]
      83818496 blocks super 1.2 [2/2] [UU]
      [======>..............]  resync = 31.0% (26044416/83818496) finish=4.7min speed=201190K/sec

unused devices: <none>
```

### 附0.3.6. 逻辑卷管理

[LVM逻辑卷管理（Logical Volume Manager）](http://www.sourceware.org/lvm2/)是红帽联机磁盘存储管理系统中的一个子系统。

这里参考其他简要说明使用流程：

创建分区参考第一节内容。

物理卷（Phisical Volume）：

```
pvcreate /dev/sdb1  # 创建物理卷
pvdisplay /dev/sdb1  # 显示物理卷
pvs /dev/sdb1  # 显示物理卷报告
pvscan  # 扫描物理卷
pvremove /dev/sdb1  # 删除物理卷
pvs
```

创建卷组（Volume Group）（可以使用分区、磁盘、磁盘阵列来创建）：

```
vgcreate vg_dlp /dev/sdb1  # 创建卷组
vgcreate vg_dlp /dev/sdb1 /dev/sdd1  # 如果要使用多个设备
vgdisplay vg_dlp  # 显示卷组
vgrename vg_dlp vg_data  # 更改卷组名称
vgdisplay vg_data
vgs  # 显示卷组报告
vgscan  # 扫描卷组

# 扩展卷组
vgextend vg_data /dev/sdc1  # 添加“sdc1”到“vg_data”

# 削减卷组
vgreduce vg_data /dev/sdc1  # 从“vg_data”移除“sdc1”

# 删除卷组
vgchange -a n vg_data  # 首先禁用目标卷组
vgremove vg_data  # 删除
```

创建逻辑卷（Logical Volume）：

```
lvcreate -L 50G -n lv_data vg_dlp  # 在卷组“vg_dlp”中创建50G的逻辑卷“lv_data”
lvcreate -l 100%FREE -n lv_data vg_dlp  # 如果使用所有空闲区域
lvdisplay /dev/vg_dlp/lv_data  # 显示逻辑卷
lvrename vg_dlp lv_data lv_storage  # 重命名逻辑卷
lvdisplay /dev/vg_dlp/lv_storage
lvs  # 显示逻辑卷报告
lvscan  # 扫描逻辑卷

# 拍摄逻辑卷的快照
lvcreate -s -L 50G -n snap-lv_storage /dev/vg_dlp/lv_storage  # 从“lv_storage”创建快照“snap-lv_storage”
lvdisplay /dev/vg_dlp/lv_storage /dev/vg_dlp/snap-lv_storage

# 扩展逻辑卷（可以在挂载时操作）
lvextend -L 70G /dev/vg_dlp/lv_storage
lvextend -L +20G /dev/vg_dlp/lv_storage  # 指定添加的容量
df -hlT  # 检查实际容量未增加
xfs_growfs /mnt  # 扩展xfs文件系统（指定挂载点）
resize2fs /dev/vg_dlp/lv_storage  # 扩展ext4文件系统
df -hlT  # 再次查看容量

# 削减逻辑卷（首先卸载目标设备，不能削减xfs文件系统）
e2fsck -f /dev/vg_dlp/lv_storage 50G  # ext4，先检查
resize2fs /dev/vg_dlp/lv_storage 50G  # ext4，削减文件系统
lvreduce -L 50G /dev/vg_dlp/lv_storage  # 削减逻辑卷

# 删除逻辑卷：卸载 -> 停止逻辑卷 -> 删除逻辑卷
lvchange -an /dev/vg_dlp/lv_storage
lvremove /dev/vg_dlp/lv_storage
```

格式化逻辑卷：

```
mkfs.ext4 /dev/vg_dlp/lv_storage
```

挂载逻辑卷到`/mnt/lv_mnt`：

```
mkdir /mnt/lv_mnt
mount /dev/vg_dlp/lv_storage /mnt/lv_mnt
```

更多内容可参看下面介绍。

#### 附0.3.6.1. 管理物理卷

这是管理物理卷（Phisical Volume）的基本操作。

首先需要[创建LVM类型的分区](#附031-添加硬盘)。

创建物理卷：

`pvcreate /dev/sdb1`

```
  Physical volume "/dev/sdb1" successfully created
```

如果要指定卷大小，如下操作：

`pvcreate --setphysicalvolumesize 50G /dev/sdb1`

```
  Physical volume "/dev/sdb1" successfully created
```

显示物理卷：

`pvdisplay /dev/sdb1`

```
  PV Name               /dev/sdb1
  VG Name
  PV Size               80.00 GiB
  Allocatable           NO
  PE Size               0
  Total PE              0
  Free PE               0
  Allocated PE          0
  PV UUID               PJnOPg-9KwO-5xJz-Z8tn-9zP7-VKn5-ADrGzy
```

更改物理卷大小：

`pvresize --setphysicalvolumesize 50G /dev/sdb1` # 更改为50G

```
  Physical volume "/dev/sdb1" changed
  1 physical volume(s) resized / 0 physical volume(s) not resized
```

`pvdisplay /dev/sdb1`

```
  PV Name               /dev/sdb1
  VG Name
  PV Size               50.00 GiB
  Allocatable           NO
  PE Size               0
  Total PE              0
  Free PE               0
  Allocated PE          0
  PV UUID               PJnOPg-9KwO-5xJz-Z8tn-9zP7-VKn5-ADrGzy
```

显示物理卷报告：

`pvs /dev/sdb1`

```
  PV         VG   Fmt  Attr PSize  PFree
  /dev/sdb1       lvm2 ---  80.00g 80.00g
```

扫描物理卷：

`pvscan`

```
  PV /dev/vda2   VG centos   lvm2 [49.51 GiB / 0    free]
  PV /dev/sdb1               lvm2 [80.00 GiB]
  Total: 2 [129.51 GiB] / in use: 1 [49.51 GiB] / in no VG: 1 [80.00 GiB]
```

删除物理卷：

`pvremove /dev/sdb1`

```
  Labels on physical volume "/dev/sdb1" successfully wiped
```

`pvdisplay /dev/sdb1`

```
  Failed to find physical volume "/dev/sdb1".
```

#### 附0.3.6.2. 管理卷组

这是管理卷组（Volume Group）的基本操作。

首先需要参照上一节创建物理卷。

创建卷组：

`vgcreate vg_dlp /dev/sdb1`

```
  Volume group "vg_dlp" successfully created
```

如果要使用多个设备，如下指定：

`vgcreate vg_dlp /dev/sdb1 /dev/sdd1`

```
  Volume group "vg_dlp" successfully created
```

显示卷组：

`vgdisplay vg_dlp`

```
  --- Volume group ---
  VG Name               vg_dlp
  System ID
  Format                lvm2
  Metadata Areas        1
  Metadata Sequence No  1
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                0
  Open LV               0
  Max PV                0
  Cur PV                1
  Act PV                1
  VG Size               80.00 GiB
  PE Size               4.00 MiB
  Total PE              20479
  Alloc PE / Size       0 / 0
  Free  PE / Size       20479 / 80.00 GiB
  VG UUID               Q3c0yC-ZgGf-E0aX-tZsv-wLe8-DETH-XDqPER
```

更改卷组名称：

`vgrename vg_dlp vg_data`

```
  Volume group "vg_dlp" successfully renamed to "vg_data"
```

`vgdisplay vg_data`

```
  --- Volume group ---
  VG Name               vg_data
  System ID
  Format                lvm2
  Metadata Areas        1
  Metadata Sequence No  2
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                0
  Open LV               0
  Max PV                0
  Cur PV                1
  Act PV                1
  VG Size               80.00 GiB
  PE Size               4.00 MiB
  Total PE              20479
  Alloc PE / Size       0 / 0
  Free  PE / Size       20479 / 80.00 GiB
  VG UUID               Q3c0yC-ZgGf-E0aX-tZsv-wLe8-DETH-XDqPER
```

显示卷组报告：

`vgs`

```
  VG      #PV #LV #SN Attr   VSize  VFree
  centos    1   2   0 wz--n- 49.51g     0
  vg_data   1   0   0 wz--n- 80.00g 80.00g
```

扫描卷组：

`vgscan`

```
  Reading all physical volumes.  This may take a while...
  Found volume group "centos" using metadata type lvm2
  Found volume group "vg_data" using metadata type lvm2
```

扩展卷组：

`vgextend vg_data /dev/sdc1` # 添加“sdc1”到“vg_data”

```
  Volume group "vg_data" successfully extended
```

`vgdisplay vg_data`

```
  --- Volume group ---
  VG Name               vg_data
  System ID
  Format                lvm2
  Metadata Areas        2
  Metadata Sequence No  4
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                0
  Open LV               0
  Max PV                0
  Cur PV                2
  Act PV                2
  VG Size               160.00 GiB
  PE Size               4.00 MiB
  Total PE              20479
  Alloc PE / Size       0 / 0
  Free  PE / Size       20479 / 160.00 GiB
  VG UUID               Q3c0yC-ZgGf-E0aX-tZsv-wLe8-DETH-XDqPER
```

削减卷组：

`vgreduce vg_data /dev/sdc1` # 从“vg_data”移除“sdc1”

```
  Removed "/dev/sdd1" from volume group "vg_data"
```

`vgdisplay vg_data`

```
  --- Volume group ---
  VG Name               vg_data
  System ID
  Format                lvm2
  Metadata Areas        1
  Metadata Sequence No  2
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                0
  Open LV               0
  Max PV                0
  Cur PV                1
  Act PV                1
  VG Size               80.00 GiB
  PE Size               4.00 MiB
  Total PE              20479
  Alloc PE / Size       0 / 0
  Free  PE / Size       20479 / 80.00 GiB
  VG UUID               Q3c0yC-ZgGf-E0aX-tZsv-wLe8-DETH-XDqPER
```

删除卷组（首先禁用目标卷组并将其删除）：

`vgchange -a n vg_data`

```
  0 logical volume(s) in volume group "vg_data" now active
```

`vgremove vg_data`

```
  Volume group "vg_data" successfully removed
```

#### 附0.3.6.3. 管理逻辑卷

这是管理逻辑卷（Logical Volume）的基本操作。

首先需要参照上一节创建卷组。

创建逻辑卷：

`lvcreate -L 50G -n lv_data vg_dlp` # 在卷组“vg_dlp”中创建50G的逻辑卷“lv_data”

```
  Logical volume "lv_data" created
```

如果使用所有空闲区域，如下指定：

`lvcreate -l 100%FREE -n lv_data vg_dlp`

```
  Logical volume "lv_data" created
```

显示逻辑卷：

`lvdisplay /dev/vg_dlp/lv_data`

```
  --- Logical volume ---
  LV Path                /dev/vg_dlp/lv_data
  LV Name                lv_data
  VG Name                vg_dlp
  LV UUID                nlTuzs-T9nC-hRIC-4Vgh-Bm9G-t4EI-kTu2NU
  LV Write Access        read/write
  LV Creation host, time dlp.srv.world, 2015-07-20 09:23:36 +0900
  LV Status              available
  # open                 0
  LV Size                80.00 GiB
  Current LE             20479
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     8192
  Block device           253:2
```

重命名逻辑卷：

`lvrename vg_dlp lv_data lv_storage` # 从“lv_data”重命名为“lv_storage”

```
  Renamed "lv_data" to "lv_storage" in volume group "vg_dlp"
```

`lvdisplay /dev/vg_dlp/lv_storage`

```
  --- Logical volume ---
  LV Path                /dev/vg_dlp/lv_storage
  LV Name                lv_storage
  VG Name                vg_dlp
  LV UUID                nlTuzs-T9nC-hRIC-4Vgh-Bm9G-t4EI-kTu2NU
  LV Write Access        read/write
  LV Creation host, time dlp.srv.world, 2015-07-20 09:23:36 +0900
  LV Status              available
  # open                 0
  LV Size                80.00 GiB
  Current LE             20479
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     8192
  Block device           253:2
```

显示逻辑卷报告：

`lvs`

```
  LV         VG     Attr       LSize  Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  root       centos -wi-ao---- 45.62g
  swap       centos -wi-ao----  3.89g
  lv_storage vg_dlp -wi-a----- 80.00g
```

扫描逻辑卷：

`lvscan`

```
  ACTIVE            '/dev/centos/swap' [3.89 GiB] inherit
  ACTIVE            '/dev/centos/root' [45.62 GiB] inherit
  ACTIVE            '/dev/vg_dlp/lv_storage' [80.00 GiB] inherit
```

拍摄逻辑卷的快照：

`lvcreate -s -L 50G -n snap-lv_storage /dev/vg_dlp/lv_storage` # 从“lv_storage”创建快照“snap-lv_storage”

```
  Logical volume "snap-lv_storage" created.
```

`lvdisplay /dev/vg_dlp/lv_storage /dev/vg_dlp/snap-lv_storage`

```
  --- Logical volume ---
  LV Path                /dev/vg_dlp/lv_storage
  LV Name                lv_storage
  VG Name                vg_dlp
  LV UUID                M7mPAd-e2BU-XIVY-z7tN-5SBS-eEiX-biB90f
  LV Write Access        read/write
  LV Creation host, time dlp.srv.world, 2015-07-20 09:33:33 +0900
  LV snapshot status     source of
                         snap-lv_storage [active]
  LV Status              available
  # open                 0
  LV Size                30.00 GiB
  Current LE             7680
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     8192
  Block device           253:2

  --- Logical volume ---
  LV Path                /dev/vg_dlp/snap-lv_storage
  LV Name                snap-lv_storage
  VG Name                vg_dlp
  LV UUID                YjbZR4-Snih-3KEE-O26y-vbQb-sLBq-Uv1CIJ
  LV Write Access        read/write
  LV Creation host, time dlp.srv.world, 2015-07-20 09:34:21 +0900
  LV snapshot status     active destination for lv_storage
  LV Status              available
  # open                 0
  LV Size                30.00 GiB
  Current LE             7680
  COW-table size         30.00 GiB
  COW-table LE           7680
  Allocated to snapshot  0.00%
  Snapshot chunk size    4.00 KiB
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     8192
  Block device           253:5
```

扩展逻辑卷（可以在挂载时操作）：

`lvextend -L 70G /dev/vg_dlp/lv_storage`

```
  Size of logical volume vg_dlp/lv_storage changed from 30.00 GiB (7680 extents) to 50.00 GiB (12800 extents).
  Logical volume lv_storage successfully resized
```

`lvdisplay /dev/vg_dlp/lv_storage`

```
  --- Logical volume ---
  LV Path                /dev/vg_dlp/lv_storage
  LV Name                lv_storage
  VG Name                vg_dlp
  LV UUID                M7mPAd-e2BU-XIVY-z7tN-5SBS-eEiX-biB90f
  LV Write Access        read/write
  LV Creation host, time dlp.srv.world, 2015-07-20 09:33:33 +0900
  LV Status              available
  # open                 1
  LV Size                70.00 GiB
  Current LE             17920
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     8192
  Block device           253:2
```

`xfs_growfs /mnt` # 对于扩展xfs文件系统（指定挂载点）

```
meta-data=/dev/mapper/vg_dlp-lv_storage isize=256    agcount=4, agsize=3276800 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=0        finobt=0
data     =                       bsize=4096   blocks=13107200, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=0
log      =internal               bsize=4096   blocks=6400, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
data blocks changed from 13107200 to 18350080
```

`resize2fs /dev/vg_dlp/lv_storage` # 扩展ext4文件系统的情况

```
resize2fs 1.42.9 (28-Dec-2013)
Filesystem at /dev/vg_dlp/lv_storage is mounted on /mnt; on-line resizing required
old_desc_blocks = 7, new_desc_blocks = 9
[ 2296.232115] EXT4-fs (dm-2): resizing filesystem from 13107200 to 18350080 blocks
[ 2296.258785] EXT4-fs (dm-2): resized filesystem to 18350080
The filesystem on /dev/vg_dlp/lv_storage is now 18350080 blocks long.
```

削减逻辑卷（首先卸载目标设备，不能削减xfs文件系统）：

`e2fsck -f /dev/vg_dlp/lv_storage 50G` # 对于ext4，先检查

```
e2fsck 1.42.9 (28-Dec-2013)
Pass 1: Checking inodes, blocks, and sizes
Pass 2: Checking directory structure
Pass 3: Checking directory connectivity
Pass 4: Checking reference counts
Pass 5: Checking group summary information
/dev/vg_dlp/lv_storage: 11/4587520 files (0.0% non-contiguous), 334056/18350080 blocks
```

`resize2fs /dev/vg_dlp/lv_storage 50G` # 对于ext4，削减文件系统

```
resize2fs 1.42.9 (28-Dec-2013)
Resizing the filesystem on /dev/vg_dlp/lv_storage to 13107200 (4k) blocks.
The filesystem on /dev/vg_dlp/lv_storage is now 13107200 blocks long.
```

`lvreduce -L 50G /dev/vg_dlp/lv_storage` # 最后削减逻辑卷

```
  WARNING: Reducing active logical volume to 50.00 GiB
  THIS MAY DESTROY YOUR DATA (filesystem etc.)
  Do you really want to reduce lv_storage? [y/n]: y
  Size of logical volume vg_dlp/lv_storage changed from 70.00 GiB (17920 extents) to 50.00 GiB (12800 extents).
  Logical volume lv_storage successfully resized
```

删除逻辑卷：

卸载 -> 停止逻辑卷 -> 删除逻辑卷

`lvchange -an /dev/vg_dlp/lv_storage`

`lvremove /dev/vg_dlp/lv_storage`

```
  Logical volume "lv_storage" successfully removed
```

#### 附0.3.6.4. 创建镜像卷

创建镜像卷（Mirroring Volume）。

例如，使用物理卷`/dev/sdb1`和`/dev/sdc1`创建镜像卷：

`vgcreate vg_mirror /dev/sdb1 /dev/sdc1` # 使用`/dev/sdb1`和`/dev/sdc1`创建卷组“vg_mirror”

```
  Logical volume "vg_mirror" created
```

`lvcreate -L 50G -m1 -n lv_mirror vg_mirror` # 创建镜像卷

```
[ 5133.283498] device-mapper: raid: Superblocks created for new array
[ 5133.285922] md/raid1:mdX: not clean -- starting background reconstruction
[ 5133.287095] md/raid1:mdX: active with 2 out of 2 mirrors
[ 5133.287932] Choosing daemon_sleep default (5 sec)
[ 5133.288688] created bitmap (50 pages) for device mdX
[ 5133.334556] mdX: bitmap file is out of date, doing full recovery
[ 5133.667257] mdX: bitmap initialized from disk: read 4 pages, set 102400 of 102400 bits
[ 5133.747852] md: resync of RAID array mdX
[ 5133.748596] md: minimum _guaranteed_  speed: 1000 KB/sec/disk.
[ 5133.749676] md: using maximum available idle IO bandwidth (but not more than 200000 KB/sec) for resync.
[ 5133.751277] md: using 128k window, over a total of 52428800k.
  Logical volume "lv_mirror" created.
```

`lvdisplay /dev/vg_mirror/lv_mirror`

```
  --- Logical volume ---
  LV Path                /dev/vg_mirror/lv_mirror
  LV Name                lv_mirror
  VG Name                vg_mirror
  LV UUID                P8dakZ-TiWn-T6b5-y6A7-Ecty-ieRZ-vGZAWX
  LV Write Access        read/write
  LV Creation host, time dlp.srv.world, 2015-07-20 13:18:20 +0900
  LV Status              available
  # open                 0
  LV Size                50.00 GiB
  Current LE             12800
  Mirrored volumes       2
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     8192
  Block device           253:6
```

如果要从已经运行的逻辑卷设置镜像卷，如下配置：

`vgextend vg_data /dev/sdc1` # 扩展卷组

```
  Volume group "vg_data" successfully extended
```

`lvconvert -m1 /dev/vg_data/lv_data /dev/sdc1` # 设置镜像卷

```
[ 5710.014313] device-mapper: raid: Superblocks created for new array
[ 5710.019478] md/raid1:mdX: not clean -- starting background reconstruction
[ 5710.020597] md/raid1:mdX: active with 2 out of 2 mirrors
[ 5710.021499] Choosing daemon_sleep default (5 sec)
[ 5710.022279] created bitmap (50 pages) for device mdX
[ 5710.173412] mdX: bitmap file is out of date, doing full recovery
[ 5710.466100] mdX: bitmap initialized from disk: read 4 pages, set 102400 of 102400 bits
[ 5710.567058] md: resync of RAID array mdX
[ 5710.567705] md: minimum _guaranteed_  speed: 1000 KB/sec/disk.
[ 5710.568658] md: using maximum available idle IO bandwidth (but not more than 200000 KB/sec) for resync.
[ 5710.570204] md: using 128k window, over a total of 52428800k.
```

`lvs` # 确认（如果“Cpy%Sync”变为“100”，则同步完成）

```
  LV      VG      Attr       LSize  Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  root    centos  -wi-ao---- 45.62g
  swap    centos  -wi-ao----  3.89g
  lv_data vg_data rwi-a-r--- 50.00g                                    1.34
```

取消设置镜像卷：

`lvconvert -m0 /dev/vg_data/lv_data` # 指定`-m0`取消设置

`lvs -a -o vg_name,name,devices,size`

```
  VG      LV      Devices        LSize
  centos  root    /dev/sda2(996) 45.62g
  centos  swap    /dev/sda2(0)    3.89g
  vg_data lv_data /dev/sdb1(0)   50.00g
```

#### 附0.3.6.5. 创建条带卷

创建条带卷（Striped Volume）。

例如，使用物理卷`/dev/sdb1`和`/dev/sdc1`创建条带卷：

`vgcreate vg_striped /dev/sdb1 /dev/sdc1` # 使用`/dev/sdb1`和`/dev/sdc1`创建卷组“vg_striped”

```
  Logical volume "vg_striped" created
```

`lvcreate -L 50G -i2 -I 64 -n lv_striped vg_striped` # 创建条带卷

```
  Wiping xfs signature on /dev/vg_striped/lv_striped.
  Logical volume "lv_striped" created.
```

`lvdisplay /dev/vg_striped/lv_striped`

```
  --- Logical volume ---
  LV Path                /dev/vg_striped/lv_striped
  LV Name                lv_striped
  VG Name                vg_striped
  LV UUID                5UoeiJ-7Ls9-qYrN-bBoV-6sJH-15HX-FlgnxK
  LV Write Access        read/write
  LV Creation host, time dlp.srv.world, 2015-07-20 14:59:30 +0900
  LV Status              available
  # open                 0
  LV Size                50.00 GiB
  Current LE             12800
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     512
  Block device           253:2
```

`lvs -a -o vg_name,name,devices,size`

```
  VG         LV         Devices                   LSize
  centos     root       /dev/sda2(996)            45.62g
  centos     swap       /dev/sda2(0)               3.89g
  vg_striped lv_striped /dev/sdb1(0),/dev/sdc1(0) 50.00g
```
